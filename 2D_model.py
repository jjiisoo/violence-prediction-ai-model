# -*- coding: utf-8 -*-
"""폭력 분류 최종.ipynb의 사본

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FfPoWlv9rwm11NVd1G7BF_2gBLD_ujjG

1. 성능평가지표 f1, AUC O
2. voting(soft) x
3. quantization o
4. cnn 계열 모델(densenet, inception-v3, resnet18, 34, 50) o
5. scheduler(reduceLRonPlateau) o
6. 증강 x
ppt
1.스팩트로그램 변환 o
2.split(val) o


grid-search
ablation=optuna
"""

# Google Drive 마운트
from google.colab import drive
drive.mount('/content/drive')

# 압축 해제 명령
!unzip -qq "/content/drive/MyDrive/Dataset_spec.zip" -d dataset1

pip install librosa matplotlib

pip install scikit-learn

# torch 관련 라이브러리
from torchvision import models, transforms
from torch.utils.data import DataLoader, Dataset
import torch
import torch.nn as nn
import torchaudio
import torch.nn.functional as F
from torch.optim.lr_scheduler import MultiStepLR, StepLR
from torchsummary import summary
import torchaudio.transforms as T

# 일반 라이브러리
import argparse
import numpy as np
import random
import os
from PIL import Image
import matplotlib.pyplot as plt
import time
from tqdm import tqdm
from sklearn.metrics import f1_score

 #스팩트로그램
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.pyplot as plt
from PIL import Image

# 스케쥴러, AUC
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torch.optim.lr_scheduler import ReduceLROnPlateau
from sklearn.metrics import f1_score
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm

class Args():
  data_type = "2d"
  scheduler = "reducelronplateau"
  model = "resnet"
  n_class = 2
  epoch = 50
  phase = "train"
  model_path = "./model_weight_2d.pth"

args = Args()

'''
class TimeMasking(object):
    def __init__(self, T=40, max_masks=1):
        self.T = T
        self.max_masks = max_masks

    def __call__(self, spec):
        for _ in range(0, self.max_masks):
            t = random.randrange(0, self.T)
            t0 = random.randrange(0, spec.shape[1] - t)
            spec[:, t0:t0+t] = 0
        return spec

class FrequencyMasking(object):
    def __init__(self, F=30, max_masks=1):
        self.F = F
        self.max_masks = max_masks

    def __call__(self, spec):
        for _ in range(0, self.max_masks):
            f = random.randrange(0, self.F)
            max_f0 = spec.shape[0] - f
            if max_f0 <= 0:
                continue
            f0 = random.randrange(0, max_f0)
            spec[f0:f0+f, :] = 0
        return spec
'''
class ImageDataset(Dataset):
    def __init__(self, directory, transform=None):
        self.directory = directory
        self.transform = transform
        self.classes = sorted(os.listdir(directory))
        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}
        self.samples = []


        for class_name in self.classes:
            class_dir = os.path.join(directory, class_name)
            for image_name in os.listdir(class_dir):
                self.samples.append((os.path.join(class_dir, image_name), self.class_to_idx[class_name]))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        image_path, label = self.samples[idx]
        image = Image.open(image_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        return image, label

# 데이터 변환 정의
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# 학습용 데이터셋 및 데이터 로더
train_dataset = ImageDataset('/content/dataset1/train_spec', transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)

# 검증용 데이터셋 및 데이터 로더
val_dataset = ImageDataset('/content/dataset1/validation_spec', transform=transform)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)

# Residual Block 정의
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample  # 입력 크기를 맞추기 위한 downsample 레이어

    def forward(self, x):
        identity = x
        if self.downsample is not None:
            identity = self.downsample(x)

        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))

        # 입력과 출력 더하기 (Residual 연결)
        out += identity
        out = F.relu(out)
        return out

# ResNet 기본 네트워크 정의
class ResNet(nn.Module):
    def __init__(self, block, layers, n_class=2):
        super(ResNet, self).__init__()
        self.in_channels = 38

        # 초기 레이어
        self.conv1 = nn.Conv2d(3, 38, kernel_size=7, stride=2, padding=3)
        self.bn1 = nn.BatchNorm2d(38)
        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # ResNet 레이어 쌓기
        self.layer1 = self._make_layer(block, 38, layers[0])
        self.layer2 = self._make_layer(block, 76, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 152, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 304, layers[3], stride=2)


        # Adaptive Pooling과 Fully Connected Layer
        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(304, n_class)

    def _make_layer(self, block, out_channels, blocks, stride=1):
        downsample = None
        if stride != 1 or self.in_channels != out_channels:
            # 입력과 출력의 크기가 다를 경우 downsample을 사용하여 크기를 맞춤
            downsample = nn.Sequential(
                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride),
                nn.BatchNorm2d(out_channels)
            )

        layers = []
        layers.append(block(self.in_channels, out_channels, stride, downsample))
        self.in_channels = out_channels
        for _ in range(1, blocks):
            layers.append(block(out_channels, out_channels))

        return nn.Sequential(*layers)

    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.pool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.adaptive_pool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)

        return x

# ResNet18 구조로 모델 생성 (기본 레이어 블록 수)
def resnet18(n_class=2):
    return ResNet(ResidualBlock, [2, 2, 2, 2], n_class)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = resnet18()

def train_model(model, train_loader, val_loader, epochs, device, args):
    model = model.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)

    if args.scheduler == 'multistep':
        scheduler = MultiStepLR(optimizer, milestones=[5, 10], gamma=0.1)
    elif args.scheduler == 'steplr':
        scheduler = StepLR(optimizer, step_size=5, gamma=0.1)
    elif args.scheduler == 'reducelronplateau':
        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)

    # Best model 저장을 위한 초기 설정
    best_val_loss = float('inf')  # 초기에는 큰 값으로 설정하여 이후에 더 작은 값으로 업데이트
    best_model_weights = None

    for epoch in range(epochs):
        # Training
        model.train()
        running_loss = 0.0
        total_batches = len(train_loader)
        correct_predictions = 0
        total_samples = 0
        all_labels = []
        all_predictions = []

        for i, (audio_signals, labels) in enumerate(tqdm(train_loader)):
            audio_signals, labels = audio_signals.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model(audio_signals)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            correct_predictions += (predicted == labels).sum().item()
            total_samples += labels.size(0)

            all_labels.extend(labels.cpu().numpy())
            all_predictions.extend(predicted.cpu().numpy())

        avg_loss = running_loss / total_batches
        accuracy = correct_predictions / total_samples
        train_f1_score = f1_score(all_labels, all_predictions, average='weighted')

        print(f"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.4f}, Train F1 Score: {train_f1_score:.4f}")

        # Validation
        model.eval()
        val_loss = 0.0
        correct_val_predictions = 0
        total_val_samples = 0
        all_val_labels = []
        all_val_predictions = []

        with torch.no_grad():
            for audio_signals, labels in tqdm(val_loader):
                audio_signals, labels = audio_signals.to(device), labels.to(device)

                outputs = model(audio_signals)
                loss = criterion(outputs, labels)
                val_loss += loss.item()

                _, predicted = torch.max(outputs, 1)
                correct_val_predictions += (predicted == labels).sum().item()
                total_val_samples += labels.size(0)

                all_val_labels.extend(labels.cpu().numpy())
                all_val_predictions.extend(predicted.cpu().numpy())

        avg_val_loss = val_loss / len(val_loader)
        val_accuracy = correct_val_predictions / total_val_samples
        val_f1_score = f1_score(all_val_labels, all_val_predictions, average='weighted')

        print(f"Epoch [{epoch + 1}/{epochs}], Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1 Score: {val_f1_score:.4f}")

        # Best 모델 저장
        if avg_val_loss < best_val_loss:
            print(f"Best model found at epoch {epoch + 1}, saving model...")
            best_val_loss = avg_val_loss
            best_model_weights = model.state_dict()  # Best 모델 가중치 저장
            early_stop_counter = 0  # 성능이 향상되었으므로 카운터 초기화
        else:
            early_stop_counter += 1  # 성능이 개선되지 않으면 카운터 증가

        # Scheduler update
        if args.scheduler == 'reducelronplateau':
            scheduler.step(avg_val_loss)
        else:
            scheduler.step()

    print('Finished Training')

    # Best 모델 저장
    if best_model_weights is not None:
        torch.save(best_model_weights, f"./best_model_weight_{args.data_type}.pth")
        print("Best model saved.")

    # Best 모델 로드
    model.load_state_dict(best_model_weights)

    return model

from torchsummary import summary

# 모델을 원하는 디바이스로 이동
model = model.to(device)

# 모델 요약 정보 출력 (입력 크기를 지정해 주어야 함, 예: (채널 수, 높이, 너비))
summary(model.cuda(),(3, 224, 224))

#model 불러오기

train_dataset = ImageDataset(directory='/content/dataset1/train_spec', transform=transform)
val_dataset = ImageDataset(directory='/content/dataset1/validation_spec', transform=transform)


# 데이터 로더 재생성
train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)

# Device 설정
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)
print(f"학습 데이터 수는 {len(train_dataset)}개 입니다."), print(f"검증 데이터 수는 {len(val_dataset)}개 입니다.")

import time

def tic():
    # 현재 시간을 전역 변수에 저장
    global start_time
    start_time = time.time()

def toc():
    # tic()이 호출된 후 경과한 시간을 계산하고 출력
    elapsed_time = time.time() - start_time

    hours = int(elapsed_time // 3600)
    minutes = int((elapsed_time % 3600) // 60)
    seconds = elapsed_time % 60  # seconds를 따로 계산
    print(f"학습에 소요된 시간은 총 : {hours}시간 {minutes}분 {seconds:.2f}초 입니다.")  # seconds를 출력

# 학습 시작 및 종료에 걸린 시간을 측정하기 위한 tic - toc

tic()

model = train_model(model, train_loader, val_loader, epochs=args.epoch, device=device, args=args)

toc()

test_dataset = ImageDataset(directory='/content/dataset1/test_spec', transform=transform)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
print(f"테스트 데이터 수는 {len(test_dataset)}개 입니다.")

import torch
import torch.nn as nn
from tqdm import tqdm
from sklearn.metrics import f1_score

def evaluate_model(model, test_loader, device, args):
    # 모델 가중치를 '/content/best_model_weight_2d.pth'에서 로드
    model.load_state_dict(torch.load('/content/best_model_weight_2d.pth', map_location=device))
    model = model.to(device)

    model.eval()

    criterion = nn.CrossEntropyLoss()

    total = 0
    correct = 0
    total_loss = 0.0
    all_labels = []
    all_predictions = []

    with torch.no_grad():
        for inputs, labels in tqdm(test_loader, desc="Evaluating", leave=False):
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            total_loss += loss.item()

            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            # F1 score 계산을 위한 레이블과 예측 값 저장
            all_labels.extend(labels.cpu().numpy())
            all_predictions.extend(predicted.cpu().numpy())

    avg_loss = total_loss / len(test_loader)
    accuracy = correct / total * 100
    # F1 score 계산, average='macro'
    f1 = f1_score(all_labels, all_predictions, average='macro')

    print(f'Test Accuracy: {accuracy:.2f}%, Avg Loss: {avg_loss:.4f}, F1 Score: {f1:.4f}')

    return accuracy, avg_loss, f1

# 모델 평가
accuracy, avg_loss, f1 = evaluate_model(model, test_loader, device=device, args=args)
print(f"테스트 데이터의 f1 score는 {f1}")